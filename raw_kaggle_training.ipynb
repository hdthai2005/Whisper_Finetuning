{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade pip\n!pip install --upgrade datasets[audio] accelerate evaluate jiwer tensorboard gradio\n!pip install transformers==4.47.0","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T04:16:52.972540Z","iopub.execute_input":"2025-04-10T04:16:52.972868Z","iopub.status.idle":"2025-04-10T04:17:17.851455Z","shell.execute_reply.started":"2025-04-10T04:16:52.972809Z","shell.execute_reply":"2025-04-10T04:17:17.850478Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import login\n\nlogin()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T04:17:17.852946Z","iopub.execute_input":"2025-04-10T04:17:17.853238Z","iopub.status.idle":"2025-04-10T04:17:18.323836Z","shell.execute_reply.started":"2025-04-10T04:17:17.853193Z","shell.execute_reply":"2025-04-10T04:17:18.322948Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"doof-ferb/vlsp2020_vinai_100h\", split=\"train\")\n\nsplit_dataset = dataset.train_test_split(test_size=0.2, seed=42)\n\ntrain_dataset = split_dataset[\"train\"]\ntest_dataset = split_dataset[\"test\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T04:18:06.151538Z","iopub.execute_input":"2025-04-10T04:18:06.151870Z","iopub.status.idle":"2025-04-10T04:19:43.659135Z","shell.execute_reply.started":"2025-04-10T04:18:06.151810Z","shell.execute_reply":"2025-04-10T04:19:43.657833Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"split_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T16:15:59.220123Z","iopub.execute_input":"2025-04-09T16:15:59.220738Z","iopub.status.idle":"2025-04-09T16:15:59.225967Z","shell.execute_reply.started":"2025-04-09T16:15:59.220707Z","shell.execute_reply":"2025-04-09T16:15:59.225308Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import WhisperFeatureExtractor\nfrom transformers import WhisperTokenizer\nfrom transformers import WhisperProcessor\nfrom datasets import Audio\n\nprocessor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v3\", language=\"Vietnamese\", task=\"transcribe\")\nfeature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-large-v3\")\ntokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-large-v3\", language=\"Vietnamese\", task=\"transcribe\")\n\n# set the sampling_rate in audio into 16kHz\ndataset = dataset.cast_column(\"audio\", Audio(sampling_rate=16000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T03:15:41.833715Z","iopub.execute_input":"2025-04-10T03:15:41.834282Z","iopub.status.idle":"2025-04-10T03:15:52.942000Z","shell.execute_reply.started":"2025-04-10T03:15:41.834248Z","shell.execute_reply":"2025-04-10T03:15:52.941339Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def prepare_dataset(batch):\n    audio = batch[\"audio\"]\n    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n    batch[\"labels\"] = tokenizer(batch[\"transcription\"]).input_ids\n    return batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T03:15:52.949388Z","iopub.execute_input":"2025-04-10T03:15:52.949781Z","iopub.status.idle":"2025-04-10T03:15:57.782747Z","shell.execute_reply.started":"2025-04-10T03:15:52.949759Z","shell.execute_reply":"2025-04-10T03:15:57.781763Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(train_dataset[0]['audio'])\nprint(train_dataset[0]['transcription'])\nprint(train_dataset[0]['audio']['sampling_rate'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T16:16:27.663631Z","iopub.execute_input":"2025-04-09T16:16:27.663965Z","iopub.status.idle":"2025-04-09T16:16:41.190478Z","shell.execute_reply.started":"2025-04-09T16:16:27.663936Z","shell.execute_reply":"2025-04-09T16:16:41.189578Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# alternate old raw column with new proccessed column\nsplit_dataset = split_dataset.map(prepare_dataset, remove_columns=split_dataset.column_names[\"train\"], num_proc=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T03:34:12.092685Z","iopub.execute_input":"2025-04-10T03:34:12.092899Z","iopub.status.idle":"2025-04-10T03:34:12.165913Z","shell.execute_reply.started":"2025-04-10T03:34:12.092878Z","shell.execute_reply":"2025-04-10T03:34:12.164880Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"split_dataset","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import WhisperForConditionalGeneration\n\nmodel = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v3\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T08:33:28.638044Z","iopub.execute_input":"2025-04-03T08:33:28.638425Z","iopub.status.idle":"2025-04-03T08:33:45.931471Z","shell.execute_reply.started":"2025-04-03T08:33:28.638380Z","shell.execute_reply":"2025-04-03T08:33:45.930723Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.generation_config.language = \"<|vi|>\"\nmodel.generation_config.task = \"transcribe\"\nmodel.generation_config.forced_decoder_ids = None\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T08:35:01.953278Z","iopub.execute_input":"2025-04-03T08:35:01.953586Z","iopub.status.idle":"2025-04-03T08:35:01.957448Z","shell.execute_reply.started":"2025-04-03T08:35:01.953562Z","shell.execute_reply":"2025-04-03T08:35:01.956558Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\n\n@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: Any\n    decoder_start_token_id: int\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n            labels = labels[:, 1:]\n\n        batch[\"labels\"] = labels\n\n        return batch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T08:37:33.853376Z","iopub.execute_input":"2025-04-03T08:37:33.853711Z","iopub.status.idle":"2025-04-03T08:37:33.860762Z","shell.execute_reply.started":"2025-04-03T08:37:33.853687Z","shell.execute_reply":"2025-04-03T08:37:33.859768Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n    processor=processor,\n    decoder_start_token_id=model.config.decoder_start_token_id,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-03T08:39:04.833176Z","iopub.execute_input":"2025-04-03T08:39:04.833704Z","iopub.status.idle":"2025-04-03T08:39:04.837773Z","shell.execute_reply.started":"2025-04-03T08:39:04.833672Z","shell.execute_reply":"2025-04-03T08:39:04.836831Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"wer\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_metrics(pred):\n    pred_ids = pred.predictions\n    label_ids = pred.label_ids\n\n    label_ids[label_ids == -100] = tokenizer.pad_token_id\n\n    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n\n    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n\n    return {\"wer\": wer}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"ds_config.json\", \"w\") as f:\n    f.write('''{\n        \"zero_optimization\": {\n            \"stage\": 2,\n            \"offload_optimizer\": {\"device\": \"cpu\", \"pin_memory\": true},\n            \"offload_param\": {\"device\": \"cpu\", \"pin_memory\": true}\n        },\n        \"fp16\": {\n            \"enabled\": true,\n            \"loss_scale\": 0,\n            \"loss_scale_window\": 1000,\n            \"hysteresis\": 2,\n            \"min_loss_scale\": 1\n        },\n        \"train_batch_size\": \"auto\",\n        \"train_micro_batch_size_per_gpu\": \"auto\"\n    }''')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-09T11:08:04.003072Z","iopub.execute_input":"2025-04-09T11:08:04.003430Z","iopub.status.idle":"2025-04-09T11:08:04.008090Z","shell.execute_reply.started":"2025-04-09T11:08:04.003388Z","shell.execute_reply":"2025-04-09T11:08:04.007238Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"/kaggle/working/whisper-large-v3-vi\",\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=16,\n    learning_rate=1e-5,\n    warmup_steps=250,\n    max_steps=2500,\n    gradient_checkpointing=True,\n    fp16=True,\n    evaluation_strategy=\"steps\",\n    per_device_eval_batch_size=1,\n    predict_with_generate=True,\n    generation_max_length=225,\n    save_steps=500,\n    eval_steps=500,\n    logging_steps=25,\n    report_to=[\"tensorboard\"],\n    load_best_model_at_end=True,\n    metric_for_best_model=\"wer\",\n    greater_is_better=False,\n    push_to_hub=True,\n    deepspeed=\"/kaggle/working/ds_config.json\",\n    save_total_limit=2,\n    save_strategy=\"steps\",\n    logging_dir=\"/kaggle/working/logs\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(\n    args=training_args,\n    model=model,\n    train_dataset=split_dataset[\"train\"],\n    eval_dataset=split_dataset[\"test\"],\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    tokenizer=processor.feature_extractor,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}