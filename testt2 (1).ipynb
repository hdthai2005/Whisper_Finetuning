{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade pip\n!pip install --upgrade datasets[audio] accelerate evaluate jiwer tensorboard gradio\n# !pip install transformers==4.47.0\n!pip install transformers==4.41.2","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip show transformers\n!pip show sentence-transformers\n!pip show peft","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T14:41:07.313226Z","iopub.execute_input":"2025-04-23T14:41:07.313924Z","iopub.status.idle":"2025-04-23T14:41:12.436250Z","shell.execute_reply.started":"2025-04-23T14:41:07.313896Z","shell.execute_reply":"2025-04-23T14:41:12.435500Z"}},"outputs":[{"name":"stdout","text":"Name: transformers\nVersion: 4.41.0\nSummary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\nHome-page: https://github.com/huggingface/transformers\nAuthor: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\nAuthor-email: transformers@huggingface.co\nLicense: Apache 2.0 License\nLocation: /usr/local/lib/python3.11/dist-packages\nRequires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\nRequired-by: kaggle-environments, peft, sentence-transformers\nName: sentence-transformers\nVersion: 3.4.1\nSummary: State-of-the-Art Text Embeddings\nHome-page: https://www.SBERT.net\nAuthor: \nAuthor-email: Nils Reimers <info@nils-reimers.de>, Tom Aarsen <tom.aarsen@huggingface.co>\nLicense: Apache 2.0\nLocation: /usr/local/lib/python3.11/dist-packages\nRequires: huggingface-hub, Pillow, scikit-learn, scipy, torch, tqdm, transformers\nRequired-by: \nName: peft\nVersion: 0.14.0\nSummary: Parameter-Efficient Fine-Tuning (PEFT)\nHome-page: https://github.com/huggingface/peft\nAuthor: The HuggingFace team\nAuthor-email: benjamin@huggingface.co\nLicense: Apache\nLocation: /usr/local/lib/python3.11/dist-packages\nRequires: accelerate, huggingface-hub, numpy, packaging, psutil, pyyaml, safetensors, torch, tqdm, transformers\nRequired-by: \n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"!apt-get update && apt-get install -y libaio-dev\n!pip install deepspeed","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T13:47:53.809138Z","iopub.execute_input":"2025-04-23T13:47:53.809373Z","iopub.status.idle":"2025-04-23T13:48:04.076729Z","shell.execute_reply.started":"2025-04-23T13:47:53.809354Z","shell.execute_reply":"2025-04-23T13:48:04.076035Z"}},"outputs":[{"name":"stdout","text":"Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\nGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]                \nGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]                                \nHit:5 http://archive.ubuntu.com/ubuntu jammy InRelease                                              \nGet:6 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [75.2 kB]\nGet:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \nGet:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,604 kB]\nGet:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB] \nGet:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]             \nGet:11 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,111 kB]        \nGet:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,845 kB]                      \nGet:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,839 kB]              \nHit:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease                 \nGet:15 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]                          \nHit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease                        \nGet:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,696 kB]                    \nGet:18 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [34.3 kB]\nGet:19 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,542 kB]  \nGet:20 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,153 kB]\nGet:21 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,272 kB]\nGet:22 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\nFetched 30.9 MB in 2s (13.3 MB/s)                            \nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following NEW packages will be installed:\n  libaio-dev\n0 upgraded, 1 newly installed, 0 to remove and 147 not upgraded.\nNeed to get 21.2 kB of archives.\nAfter this operation, 71.7 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libaio-dev amd64 0.3.112-13build1 [21.2 kB]\nFetched 21.2 kB in 0s (62.3 kB/s)     \nSelecting previously unselected package libaio-dev:amd64.\n(Reading database ... 128691 files and directories currently installed.)\nPreparing to unpack .../libaio-dev_0.3.112-13build1_amd64.deb ...\nUnpacking libaio-dev:amd64 (0.3.112-13build1) ...\nSetting up libaio-dev:amd64 (0.3.112-13build1) ...\nProcessing triggers for man-db (2.10.2-1) ...\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(token=\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T14:22:47.541011Z","iopub.execute_input":"2025-04-23T14:22:47.541495Z","iopub.status.idle":"2025-04-23T14:22:51.612349Z","shell.execute_reply.started":"2025-04-23T14:22:47.541470Z","shell.execute_reply":"2025-04-23T14:22:51.611431Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset = load_dataset(\"doof-ferb/vlsp2020_vinai_100h\", split=\"train\")\n# split_dataset = dataset.train_test_split(test_size=0.2, seed=42)\n\nsmall_dataset = dataset.select(range(1000))\nsplit_dataset = small_dataset.train_test_split(test_size=0.2, seed=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T14:21:10.021692Z","iopub.execute_input":"2025-04-23T14:21:10.022498Z","iopub.status.idle":"2025-04-23T14:22:47.539759Z","shell.execute_reply.started":"2025-04-23T14:21:10.022471Z","shell.execute_reply":"2025-04-23T14:22:47.538871Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/1.66k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2802f037c5574180beec2e3ec01cc84b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f900c6c5f9a47ff90dba440bf5290ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Resolving data files:   0%|          | 0/35 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2bc3c65fa5cb4e789e94839d49e0cb28"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0/35 [00:00<?, ?files/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75d19800ee0542b083bf687200d99d14"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00035.parquet:   0%|          | 0.00/489M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42a956ff508a43e688bd7d67e6b294cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00035.parquet:   0%|          | 0.00/447M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04b7ef2720ac4ba98a90b0ec3b3e1fc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00002-of-00035.parquet:   0%|          | 0.00/235M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"505c1ba667ee42e091f655a4f33ee097"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00003-of-00035.parquet:   0%|          | 0.00/430M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"026078af47544c0baf904782746c4379"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00004-of-00035.parquet:   0%|          | 0.00/305M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39d06351393f49d7b2c74a8a7c8751f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00005-of-00035.parquet:   0%|          | 0.00/263M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"144cf6ca66d648ca9a1038a867d2acea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00006-of-00035.parquet:   0%|          | 0.00/381M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57e03b8f95f64526a89982cc2c332b57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00007-of-00035.parquet:   0%|          | 0.00/224M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16064bf7df8e4736964e1dc7e0a53354"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00008-of-00035.parquet:   0%|          | 0.00/229M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"faf962923fa34bda95126280465bc405"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00009-of-00035.parquet:   0%|          | 0.00/381M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29e0b6354c7b416fb2e9b2ffcf563ddf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00010-of-00035.parquet:   0%|          | 0.00/463M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cd69a1edeec74fefb459d667c5627fb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00011-of-00035.parquet:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"784b0b0ff452484fba5796b8bc71108b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00012-of-00035.parquet:   0%|          | 0.00/395M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e519f7ca8c90471598f2061937eb0c2c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00013-of-00035.parquet:   0%|          | 0.00/383M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa98c1eba87540db86a54ad6648b98cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00014-of-00035.parquet:   0%|          | 0.00/324M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c41ce2eedbd40759861a7e11d8c9444"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00015-of-00035.parquet:   0%|          | 0.00/329M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"295cc2ca34154730b4e193ed3d939840"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00016-of-00035.parquet:   0%|          | 0.00/411M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48a40131d98f4b52b9da1b19c6714919"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00017-of-00035.parquet:   0%|          | 0.00/373M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f98faa49934407d8fb031c5a6389825"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00018-of-00035.parquet:   0%|          | 0.00/459M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b80f400e0a084a558180f496fc68cb85"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00019-of-00035.parquet:   0%|          | 0.00/393M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70413faeff7f43dcabefff136cb75727"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00020-of-00035.parquet:   0%|          | 0.00/302M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99335f0fcc4042ccb9b8ffed91aac2bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00021-of-00035.parquet:   0%|          | 0.00/275M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"913a8f959d3b47e2894b0cdf1074f806"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00022-of-00035.parquet:   0%|          | 0.00/251M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14d46f4920844af3b298cefb3554a4a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00023-of-00035.parquet:   0%|          | 0.00/309M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"380d12ac83c84186838001839b4b5690"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00024-of-00035.parquet:   0%|          | 0.00/321M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43cce693acad49c88ad22e3e4527adf0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00025-of-00035.parquet:   0%|          | 0.00/317M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5740343de45a41e2a1c9a3ba5408058d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00026-of-00035.parquet:   0%|          | 0.00/320M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4700bdad70674076b5f377024ce4128d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00027-of-00035.parquet:   0%|          | 0.00/245M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8cdaf55f50a4c60b91a870589aaf857"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00028-of-00035.parquet:   0%|          | 0.00/232M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffd7aaaca95b4c00b1b70e6d2b570520"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00029-of-00035.parquet:   0%|          | 0.00/225M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da84e680696743d7bc1cf09511a80aad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00030-of-00035.parquet:   0%|          | 0.00/227M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06e16c31a7b74bf49cd63c85e18221bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00031-of-00035.parquet:   0%|          | 0.00/255M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"095ad3a60319426cb1330bea9eb55d48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00032-of-00035.parquet:   0%|          | 0.00/343M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e5134f2ce3846d39b2fc5f1d297c149"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00033-of-00035.parquet:   0%|          | 0.00/337M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccef49baefae475fb09d84018a2f0dd4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00034-of-00035.parquet:   0%|          | 0.00/339M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"566d3860d1674d1ca2816313774b50bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/56427 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80d3283820f948c4af5e5c6b56ecd05f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading dataset shards:   0%|          | 0/23 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e96dc3a279f444529ffcdd07687ce5cd"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"split_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T13:40:47.821413Z","iopub.execute_input":"2025-04-23T13:40:47.821908Z","iopub.status.idle":"2025-04-23T13:40:47.827060Z","shell.execute_reply.started":"2025-04-23T13:40:47.821883Z","shell.execute_reply":"2025-04-23T13:40:47.826454Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['audio', 'transcription'],\n        num_rows: 800\n    })\n    test: Dataset({\n        features: ['audio', 'transcription'],\n        num_rows: 200\n    })\n})"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"from transformers import WhisperFeatureExtractor\nfrom transformers import WhisperTokenizer\nfrom transformers import WhisperProcessor\nfrom datasets import Audio\n\nprocessor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v3\", language=\"Vietnamese\", task=\"transcribe\")\nfeature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-large-v3\")\ntokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-large-v3\", language=\"Vietnamese\", task=\"transcribe\")\n\n# set the sampling_rate in audio into 16kHz\nsplit_dataset = split_dataset.cast_column(\"audio\", Audio(sampling_rate=16000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T14:25:21.061193Z","iopub.execute_input":"2025-04-23T14:25:21.061826Z","iopub.status.idle":"2025-04-23T14:25:26.382864Z","shell.execute_reply.started":"2025-04-23T14:25:21.061801Z","shell.execute_reply":"2025-04-23T14:25:26.382113Z"}},"outputs":[{"name":"stderr","text":"The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"047061b171e146d3af7a818aa66487a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50c85a68aa634666a95293d06c5b36df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d14f9cf75b4340479c4f964c2ce18103"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9730c44581c340b9b638746dc586f118"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5bb59e46c814dbaadbf95481254a398"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9228d5e4c204da18d3a01b71489cd2a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1fb96e96ed949cd8d6a86bb8b3961e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87a4bbb6fb3949cf951b8d2830203f4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.07k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae246a9b708048a3a0da7836d7f0b47e"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"    def prepare_dataset(batch):\n        input_features = []\n        labels = []\n        for audio, transcription in zip(batch[\"audio\"], batch[\"transcription\"]):\n            if isinstance(audio, dict) and \"array\" in audio and \"sampling_rate\" in audio:\n                input_features.append(\n                    feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n                )\n                labels.append(tokenizer(transcription).input_ids)\n            else:\n                raise ValueError(f\"Unexpected audio format: {audio}\")\n\n        return {\"input_features\": input_features, \"labels\": labels}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T14:42:30.596429Z","iopub.execute_input":"2025-04-23T14:42:30.597142Z","iopub.status.idle":"2025-04-23T14:42:30.601694Z","shell.execute_reply.started":"2025-04-23T14:42:30.597115Z","shell.execute_reply":"2025-04-23T14:42:30.600941Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"split_dataset = split_dataset.map(prepare_dataset,\n                                      remove_columns=split_dataset[\"train\"].column_names,\n                                      num_proc=4,\n                                      batched=True, batch_size=20)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-23T14:42:33.245620Z","iopub.execute_input":"2025-04-23T14:42:33.246430Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=12):   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32c4626c6c0c435a8d1b4a65ab7d0082"}},"metadata":{}},{"name":"stderr","text":"2025-04-23 14:43:30.545763: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-23 14:43:30.545763: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-23 14:43:30.545767: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-23 14:43:30.545763: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-23 14:43:30.545957: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-23 14:43:30.545963: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-23 14:43:30.545965: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-23 14:43:30.545968: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-23 14:43:30.546081: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-23 14:43:30.546084: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-23 14:43:30.546087: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-04-23 14:43:30.546092: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745419410.881151    1045 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745419410.881175    1038 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745419410.881147    1037 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745419410.881138    1046 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745419410.881254    1047 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745419410.881269    1043 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745419410.881268    1036 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745419410.881275    1040 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745419410.881305    1044 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745419410.881320    1041 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745419410.881318    1042 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745419410.881344    1039 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745419410.980841    1047 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1745419410.980827    1042 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1745419410.980830    1040 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1745419410.980839    1038 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1745419410.980947    1046 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1745419410.980959    1044 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1745419410.980985    1037 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1745419410.981036    1039 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1745419410.981082    1036 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1745419410.981106    1043 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1745419410.981143    1045 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1745419410.980946    1041 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"from transformers import WhisperForConditionalGeneration\n\nmodel = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v3\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\nmodel.generation_config.language = \"<|vi|>\"\nmodel.generation_config.task = \"transcribe\"\nmodel.generation_config.forced_decoder_ids = None\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Union\n\n@dataclass\nclass DataCollatorSpeechSeq2SeqWithPadding:\n    processor: Any\n    decoder_start_token_id: int\n\n    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n\n        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n\n        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n\n        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n            labels = labels[:, 1:]\n\n        batch[\"labels\"] = labels\n\n        return batch","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n    processor=processor,\n    decoder_start_token_id=model.config.decoder_start_token_id,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"wer\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_metrics(pred):\n    pred_ids = pred.predictions\n    label_ids = pred.label_ids\n\n    label_ids[label_ids == -100] = tokenizer.pad_token_id\n\n    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n\n    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n\n    return {\"wer\": wer}","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(\"ds_config.json\", \"w\") as f:\n    f.write('''{\n        \"zero_optimization\": {\n            \"stage\": 2,\n            \"offload_optimizer\": {\"device\": \"cpu\", \"pin_memory\": true},\n            \"offload_param\": {\"device\": \"cpu\", \"pin_memory\": true}\n        },\n        \"fp16\": {\n            \"enabled\": true,\n            \"loss_scale\": 0,\n            \"loss_scale_window\": 1000,\n            \"hysteresis\": 2,\n            \"min_loss_scale\": 1\n        },\n        \"train_batch_size\": \"auto\",\n        \"train_micro_batch_size_per_gpu\": \"auto\"\n    }''')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"/kaggle/working/whisper-large-v3-vi\",\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=16,\n    learning_rate=1e-5,\n    warmup_steps=250,\n    max_steps=2500,\n    gradient_checkpointing=True,\n    fp16=True,\n    eval_strategy=\"steps\",\n    per_device_eval_batch_size=1,\n    predict_with_generate=True,\n    generation_max_length=225,\n    save_steps=500,\n    eval_steps=500,\n    logging_steps=25,\n    report_to=[\"tensorboard\"],\n    load_best_model_at_end=True,\n    metric_for_best_model=\"wer\",\n    greater_is_better=False,\n    push_to_hub=False,\n    deepspeed=\"/kaggle/working/ds_config.json\",\n    save_total_limit=2,\n    save_strategy=\"steps\",\n    logging_dir=\"/kaggle/working/logs\"\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer\n\ntrainer = Seq2SeqTrainer(\n    args=training_args,\n    model=model,\n    train_dataset=split_dataset[\"train\"],\n    eval_dataset=split_dataset[\"test\"],\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n    tokenizer=processor.feature_extractor,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}